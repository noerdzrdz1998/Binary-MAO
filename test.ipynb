{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "32b531b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing dataset: twonorm with F1 metric\n",
            "Processing dataset: spectfheart with F1 metric\n",
            "Processing dataset: appendicitis with F1 metric\n",
            "Processing dataset: pima with F1 metric\n",
            "Processing dataset: Iris with F1 metric\n",
            "Processing dataset: titanic with F1 metric\n",
            "Processing dataset: mammographic with F1 metric\n",
            "Processing dataset: Nutt with F1 metric\n",
            "Processing dataset: spambase with F1 metric\n",
            "Processing dataset: haberman with F1 metric\n",
            "Processing dataset: heart with F1 metric\n",
            "Processing dataset: australian with F1 metric\n",
            "Processing dataset: sonar with F1 metric\n",
            "Processing dataset: ring with F1 metric\n",
            "Processing dataset: wdbc with F1 metric\n",
            "Processing dataset: hepatitis with F1 metric\n",
            "Processing dataset: phoneme with F1 metric\n",
            "Processing dataset: banana with F1 metric\n",
            "Processing dataset: bands with F1 metric\n",
            "Processing dataset: ionosphere with F1 metric\n",
            "Processing dataset: bupa with F1 metric\n",
            "Processing dataset: wisconsin with F1 metric\n"
          ]
        }
      ],
      "source": [
        "from data_loader import process_files\n",
        "from feature_selection_MAO import model_with_metaheuristic_feature_selection\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load datasets\n",
        "datasets, dataset_names = process_files(\"all_datasets\")\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"SVM\": partial(SVC, kernel=\"linear\", max_iter=1000),\n",
        "    \"k-NN (k=1)\": partial(KNeighborsClassifier, n_neighbors=1),\n",
        "    \"k-NN (k=3)\": partial(KNeighborsClassifier, n_neighbors=3),\n",
        "    \"k-NN (k=5)\": partial(KNeighborsClassifier, n_neighbors=5),\n",
        "    \"Bayesian\": GaussianNB,\n",
        "    \"Logistic Regression\": partial(LogisticRegression, max_iter=200),\n",
        "    \"MLP\": partial(MLPClassifier, max_iter=300),\n",
        "    \"Random Forest\": partial(RandomForestClassifier, n_estimators=100),\n",
        "    \"Decision Tree\": DecisionTreeClassifier,\n",
        "}\n",
        "\n",
        "# Stratified K-Fold configuration\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize results storage\n",
        "f1_results = []\n",
        "time_results = []\n",
        "selected_features_results = []\n",
        "\n",
        "# Process each dataset\n",
        "for dataset, dataset_name in zip(datasets, dataset_names):\n",
        "    print(f\"Processing dataset: {dataset_name}\")\n",
        "    X = dataset.iloc[:, :-1].values\n",
        "    y = dataset.iloc[:, -1].values\n",
        "\n",
        "    dataset_f1 = {\"Dataset\": dataset_name}\n",
        "    dataset_time = {\"Dataset\": dataset_name}\n",
        "    dataset_features = {\"Dataset\": dataset_name}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Without feature selection\n",
        "        fold_f1_scores = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        for train_idx, test_idx in kf.split(X, y):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            model_instance = model()\n",
        "            model_instance.fit(X_train, y_train)\n",
        "            y_pred = model_instance.predict(X_test)\n",
        "            fold_f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "        mean_f1_without = np.mean(fold_f1_scores)\n",
        "        elapsed_time_without = time.time() - start_time\n",
        "\n",
        "        # Save results without feature selection\n",
        "        dataset_f1[f\"{model_name}\"] = mean_f1_without\n",
        "        dataset_time[f\"{model_name}\"] = elapsed_time_without\n",
        "\n",
        "        # With feature selection (MAO)\n",
        "        start_time = time.time()\n",
        "\n",
        "        meta_results = model_with_metaheuristic_feature_selection(\n",
        "            datasets=[dataset],\n",
        "            datasets_names=[dataset_name],\n",
        "            model=model,\n",
        "            mao_metric = \"alpha\",  ##alpha, alpha-mean o sklearn metric\n",
        "            evaluation_metric = f1_score, # sklearn metric\n",
        "            validation_method=\"stratified_kfold\",\n",
        "            validation_params={\"n_splits\": 5, \"shuffle\": True, \"random_state\": 42},\n",
        "            pop_size=50,\n",
        "            max_iter=1000,\n",
        "            early_stopping_steps=20,\n",
        "            transition_prob=0.5,\n",
        "            injury_prob=0.3,\n",
        "            regeneration_prob=0.1,\n",
        "            lambda_factor=0.5,\n",
        "            k=3,\n",
        "            number_of_steps = 100\n",
        "        )\n",
        "\n",
        "        elapsed_time_with = time.time() - start_time\n",
        "        mean_f1_with = meta_results[dataset_name][\"mean_metric\"]\n",
        "        selected_features = meta_results[dataset_name][\"selected_features\"]\n",
        "\n",
        "        # Save results with feature selection\n",
        "        dataset_f1[f\"{model_name}-MAO\"] = mean_f1_with\n",
        "        dataset_time[f\"{model_name}-MAO\"] = elapsed_time_with\n",
        "        dataset_features[f\"{model_name}-Selected Features\"] = selected_features\n",
        "\n",
        "    # Append results\n",
        "    f1_results.append(dataset_f1)\n",
        "    time_results.append(dataset_time)\n",
        "    selected_features_results.append(dataset_features)\n",
        "\n",
        "# Save results to Excel\n",
        "f1_df = pd.DataFrame(f1_results)\n",
        "time_df = pd.DataFrame(time_results)\n",
        "features_df = pd.DataFrame(selected_features_results)\n",
        "\n",
        "f1_df.to_excel(\"alfa-mean_Results.xlsx\", index=False)\n",
        "time_df.to_excel(\"alfa-mean_Time_Results.xlsx\", index=False)\n",
        "features_df.to_excel(\"alfa-mean_Selected_Features.xlsx\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "required_libs": []
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
